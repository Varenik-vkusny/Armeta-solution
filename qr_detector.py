import cv2
import ultralytics
from pyzbar.pyzbar import decode
import numpy as np
from ultralytics import YOLO
from concurrent.futures import ThreadPoolExecutor
import time

# --- –ó–ê–ì–†–£–ó–ö–ê –ú–û–î–ï–õ–ò YOLO ---
MODEL_PATH = "best.pt"
try:
    yolo_model = YOLO(MODEL_PATH)
    print(f"--- –ú–æ–¥–µ–ª—å YOLO ('{MODEL_PATH}') —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–∞. ---")
except Exception as e:
    print(
        f"--- [–ü–†–ï–î–£–ü–†–ï–ñ–î–ï–ù–ò–ï] –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª—å YOLO '{MODEL_PATH}'. –û—à–∏–±–∫–∞: {e} ---"
    )
    yolo_model = None


def _run_pyzbar_fast(image_to_scan, methods=["grayscale", "adaptive_thresh"]):
    """
    [–£–õ–¨–¢–†–ê-–ë–´–°–¢–†–ê–Ø –í–ï–†–°–ò–Ø]
    –ó–∞–ø—É—Å–∫–∞–µ—Ç —Ç–æ–ª—å–∫–æ —Å–∞–º—ã–µ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–µ –º–µ—Ç–æ–¥—ã Pyzbar.
    –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é: grayscale + adaptive_thresh (–æ–Ω–∏ –Ω–∞—Ö–æ–¥—è—Ç 90%+ –≤—Å–µ—Ö QR)
    """
    found_objects = []
    gray = cv2.cvtColor(image_to_scan, cv2.COLOR_BGR2GRAY)

    # –°–ª–æ–≤–∞—Ä—å –≤—Å–µ—Ö –≤–æ–∑–º–æ–∂–Ω—ã—Ö –º–µ—Ç–æ–¥–æ–≤
    all_methods = {
        "grayscale": gray,
        "adaptive_thresh": None,  # –°–æ–∑–¥–∞–¥–∏–º –ø–æ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—é
        "otsu_thresh": None,
        "original_bgr": image_to_scan,
    }

    for method_name in methods:
        if method_name not in all_methods:
            continue

        # –õ–µ–Ω–∏–≤–æ–µ —Å–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
        if method_name == "adaptive_thresh" and all_methods[method_name] is None:
            blurred = cv2.GaussianBlur(gray, (3, 3), 0)
            all_methods[method_name] = cv2.adaptiveThreshold(
                blurred, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 31, 7
            )
        elif method_name == "otsu_thresh" and all_methods[method_name] is None:
            blurred = cv2.GaussianBlur(gray, (3, 3), 0)
            all_methods[method_name] = cv2.threshold(
                blurred, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU
            )[1]

        image_for_decode = all_methods[method_name]

        try:
            qrcodes = decode(image_for_decode)
            for qr in qrcodes:
                found_objects.append({"qr_obj": qr, "source": f"pyzbar_{method_name}"})
        except Exception as e:
            pass  # –¢–∏—Ö–æ –∏–≥–Ω–æ—Ä–∏—Ä—É–µ–º –æ—à–∏–±–∫–∏ –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏

    return found_objects


def _process_scale(scale, input_image, orig_w, orig_h):
    """
    –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ–¥–Ω–æ–≥–æ –º–∞—Å—à—Ç–∞–±–∞ (–¥–ª—è –ø–∞—Ä–∞–ª–ª–µ–ª–∏–∑–∞—Ü–∏–∏)
    """
    if scale == 1.0:
        scaled_image = input_image
    else:
        try:
            interpolation_method = cv2.INTER_AREA if scale < 1.0 else cv2.INTER_CUBIC
            scaled_image = cv2.resize(
                input_image,
                (int(orig_w * scale), int(orig_h * scale)),
                interpolation=interpolation_method,
            )
        except Exception:
            return []

    if scaled_image is None or scaled_image.size == 0:
        return []

    # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ 2 —Å–∞–º—ã—Ö —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã—Ö –º–µ—Ç–æ–¥–∞
    found_objects = _run_pyzbar_fast(
        scaled_image, methods=["grayscale", "adaptive_thresh"]
    )

    # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –æ–±—Ä–∞—Ç–Ω–æ –∫ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–º—É —Ä–∞–∑–º–µ—Ä—É
    results = []
    for item in found_objects:
        qr_obj = item["qr_obj"]
        source = item["source"]
        data_bytes = qr_obj.data
        points_scaled = np.array(qr_obj.polygon, dtype=np.float32)

        if data_bytes is not None:
            points_original = points_scaled / scale
            results.append(
                {
                    "data": data_bytes,
                    "points": points_original,
                    "source": f"{source}_scale_{scale}x",
                }
            )

    return results


def is_duplicate(new_points, existing_qrs, threshold=0.7):
    """
    [–û–ü–¢–ò–ú–ò–ó–ò–†–û–í–ê–ù–û] –ü–æ—Ä–æ–≥ —Å–Ω–∏–∂–µ–Ω –¥–æ 0.7 –¥–ª—è –±–æ–ª–µ–µ —Å—Ç—Ä–æ–≥–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏
    """
    new_box = cv2.boundingRect(new_points.astype(int))
    nx, ny, nw, nh = new_box

    for qr in existing_qrs:
        existing_box = cv2.boundingRect(qr["points"].astype(int))
        ex, ey, ew, eh = existing_box

        # –ë—ã—Å—Ç—Ä–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞: –µ—Å–ª–∏ bbox'—ã –≤–æ–æ–±—â–µ –Ω–µ –ø–µ—Ä–µ—Å–µ–∫–∞—é—Ç—Å—è
        if nx + nw < ex or ex + ew < nx or ny + nh < ey or ey + eh < ny:
            continue

        # –í—ã—á–∏—Å–ª—è–µ–º IoU
        ix = max(nx, ex)
        iy = max(ny, ey)
        iw = min(nx + nw, ex + ew) - ix
        ih = min(ny + nh, ey + eh) - iy

        if iw > 0 and ih > 0:
            intersection_area = iw * ih
            union_area = (nw * nh) + (ew * eh) - intersection_area
            iou = intersection_area / union_area

            if iou > threshold:
                return True

    return False


def add_qr_code_detections_turbo(
    input_image_np,
    existing_page_data,
    annotation_start_index: int,
    use_parallel=True,
    early_stop=True,
):
    """
    üöÄ –¢–£–†–ë–û-–í–ï–†–°–ò–Ø: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –¥–µ—Ç–µ–∫—Ç–æ—Ä

    –ü–∞—Ä–∞–º–µ—Ç—Ä—ã:
    - use_parallel: –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É –º–∞—Å—à—Ç–∞–±–æ–≤ (–±—ã—Å—Ç—Ä–µ–µ –Ω–∞ –º–æ—â–Ω—ã—Ö CPU)
    - early_stop: –æ—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞—Ç—å—Å—è –ø–æ—Å–ª–µ –Ω–∞—Ö–æ–∂–¥–µ–Ω–∏—è QR-–∫–æ–¥–æ–≤ (—ç–∫–æ–Ω–æ–º–∏—Ç –≤—Ä–µ–º—è)
    """
    start_time = time.time()
    print("--- üöÄ –¢–£–†–ë–û-–î–ï–¢–ï–ö–¢–û–†: –ó–∞–ø—É—Å–∫ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞ QR-–∫–æ–¥–æ–≤...")

    found_qrs = []
    image_with_boxes = input_image_np.copy()
    current_annotation_index = annotation_start_index
    orig_h, orig_w, _ = input_image_np.shape

    # ==============================================================================
    # –°–¢–†–ê–¢–ï–ì–ò–Ø 1: –ù–∞—á–∏–Ω–∞–µ–º —Å –Ω–∞—Ç–∏–≤–Ω–æ–≥–æ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏—è (scale=1.0)
    # ==============================================================================
    print("--- [–°—Ç—Ä–∞—Ç–µ–≥–∏—è 1] –ë—ã—Å—Ç—Ä–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –Ω–∞—Ç–∏–≤–Ω–æ–º —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–∏...")

    native_results = _process_scale(1.0, input_image_np, orig_w, orig_h)
    for item in native_results:
        if not is_duplicate(item["points"], found_qrs):
            found_qrs.append(item)

    print(f"    –ù–∞–π–¥–µ–Ω–æ: {len(found_qrs)} QR-–∫–æ–¥–æ–≤")

    # Early stop: –µ—Å–ª–∏ –Ω–∞—à–ª–∏ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ QR-–∫–æ–¥–æ–≤ –Ω–∞ –Ω–∞—Ç–∏–≤–Ω–æ–º —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–∏
    if early_stop and len(found_qrs) > 0:
        print("    ‚úì QR-–∫–æ–¥—ã –Ω–∞–π–¥–µ–Ω—ã! –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –º–∞—Å—à—Ç–∞–±—ã.")
    else:
        # ==============================================================================
        # –°–¢–†–ê–¢–ï–ì–ò–Ø 2: –ú—É–ª—å—Ç–∏–º–∞—Å—à—Ç–∞–±–Ω—ã–π –ø–æ–∏—Å–∫ (–ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–π –∏–ª–∏ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω—ã–π)
        # ==============================================================================
        print("--- [–°—Ç—Ä–∞—Ç–µ–≥–∏—è 2] –ú—É–ª—å—Ç–∏–º–∞—Å—à—Ç–∞–±–Ω—ã–π –ø–æ–∏—Å–∫...")

        # –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –Ω–∞–±–æ—Ä –º–∞—Å—à—Ç–∞–±–æ–≤: —Ç–æ–ª—å–∫–æ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ
        additional_scales = [0.5, 2.0]  # –£–º–µ–Ω—å—à–∏–ª–∏ —Å [0.5, 2.0] (–±—ã–ª–æ 3 scale)

        if use_parallel:
            # –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –º–∞—Å—à—Ç–∞–±–æ–≤
            with ThreadPoolExecutor(max_workers=2) as executor:
                futures = [
                    executor.submit(
                        _process_scale, scale, input_image_np, orig_w, orig_h
                    )
                    for scale in additional_scales
                ]

                for future in futures:
                    try:
                        results = future.result(timeout=5.0)  # –¢–∞–π–º–∞—É—Ç –¥–ª—è –∑–∞—â–∏—Ç—ã
                        for item in results:
                            if not is_duplicate(item["points"], found_qrs):
                                found_qrs.append(item)
                    except Exception as e:
                        print(f"    ‚ö† –û—à–∏–±–∫–∞ –≤ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–µ: {e}")
        else:
            # –ü–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞
            for scale in additional_scales:
                results = _process_scale(scale, input_image_np, orig_w, orig_h)
                for item in results:
                    if not is_duplicate(item["points"], found_qrs):
                        found_qrs.append(item)

        print(f"    –ù–∞–π–¥–µ–Ω–æ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ: {len(found_qrs)} QR-–∫–æ–¥–æ–≤ (–≤—Å–µ–≥–æ)")

    # ==============================================================================
    # –°–¢–†–ê–¢–ï–ì–ò–Ø 3: YOLO (—Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ Pyzbar –Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞—à–µ–ª)
    # ==============================================================================
    if yolo_model and len(found_qrs) == 0:
        print("--- [–°—Ç—Ä–∞—Ç–µ–≥–∏—è 3] Pyzbar –Ω–µ –Ω–∞—à–µ–ª - –ø—Ä–æ–±—É–µ–º YOLO...")
        try:
            # –ü–æ–≤—ã—à–µ–Ω–Ω—ã–π conf –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è
            results = yolo_model(input_image_np, conf=0.40, verbose=False, imgsz=640)
            boxes = results[0].boxes.xyxy.cpu().numpy()

            if len(boxes) > 0:
                print(f"    YOLO –Ω–∞—à–µ–ª {len(boxes)} –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤...")

                for box in boxes:
                    x1, y1, x2, y2 = map(int, box)
                    box_w = x2 - x1
                    box_h = y2 - y1

                    # –ú–µ–Ω—å—à–∏–π padding –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è
                    pad_x = int(box_w * 0.10)
                    pad_y = int(box_h * 0.10)
                    y_start = max(0, y1 - pad_y)
                    y_end = min(orig_h, y2 + pad_y)
                    x_start = max(0, x1 - pad_x)
                    x_end = min(orig_w, x2 + pad_x)

                    qr_crop = input_image_np[y_start:y_end, x_start:x_end]

                    if qr_crop.size == 0:
                        continue

                    # –¢–æ–ª—å–∫–æ grayscale –º–µ—Ç–æ–¥ –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏
                    decoded_objects = _run_pyzbar_fast(qr_crop, methods=["grayscale"])

                    if decoded_objects:
                        for item in decoded_objects:
                            qr_obj = item["qr_obj"]
                            source = item["source"]
                            data_bytes = qr_obj.data
                            points_crop = np.array(qr_obj.polygon, dtype=np.float32)

                            if data_bytes is not None:
                                points_original = points_crop + [x_start, y_start]

                                if not is_duplicate(points_original, found_qrs):
                                    found_qrs.append(
                                        {
                                            "data": data_bytes,
                                            "points": points_original,
                                            "source": f"yolo_confirmed_by_{source}",
                                        }
                                    )
                                    print("    ‚úì YOLO –Ω–∞—à–µ–ª –Ω–æ–≤—ã–π QR!")
                                    break  # Early stop –ø–æ—Å–ª–µ –ø–µ—Ä–≤–æ–π –Ω–∞—Ö–æ–¥–∫–∏ –≤ —ç—Ç–æ–º crop

        except Exception as e:
            print(f"    ‚ö† –û—à–∏–±–∫–∞ YOLO: {e}")

    # ==============================================================================
    # –§–ò–ù–ê–õ–¨–ù–ê–Ø –û–ë–†–ê–ë–û–¢–ö–ê
    # ==============================================================================
    if found_qrs:
        print(f"--- ‚úì –ù–∞–π–¥–µ–Ω–æ {len(found_qrs)} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö QR-–∫–æ–¥–æ–≤")
        for item in found_qrs:
            points = item["points"]
            source = item["source"]

            x, y, w, h = cv2.boundingRect(points.astype(int))

            annotation = {
                f"annotation_{current_annotation_index}": {
                    "category": "qr_code",
                    "bbox": {"x": x, "y": y, "width": w, "height": h},
                    "area": w * h,
                }
            }
            existing_page_data["annotations"].append(annotation)

            # –†–∏—Å—É–µ–º —Ä–∞–º–∫—É
            pts = points.astype(np.int32).reshape((-1, 1, 2))
            cv2.polylines(
                image_with_boxes, [pts], isClosed=True, color=(0, 255, 0), thickness=3
            )
            cv2.putText(
                image_with_boxes,
                f"QR",
                (x, y - 10),
                cv2.FONT_HERSHEY_SIMPLEX,
                0.9,
                (0, 255, 0),
                2,
            )
            current_annotation_index += 1
    else:
        print("--- QR-–∫–æ–¥—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")

    elapsed = time.time() - start_time
    print(f"--- ‚è± –í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {elapsed:.2f}s")

    return image_with_boxes, existing_page_data, current_annotation_index


# –î–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
add_qr_code_detections_ultimate = add_qr_code_detections_turbo
